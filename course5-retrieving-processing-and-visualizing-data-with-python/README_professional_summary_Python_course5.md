ğŸ“˜ Course 5: Capstone â€“ Retrieving, Processing, and Visualizing Data with Python

Specialization: Python for Everybody
Platform: Coursera â€“ University of Michigan
Directory: course5-retrieving-processing-and-visualizing-data-with-python

â¸»

ğŸ¯ Course Objective

This capstone course brought together every major skill developed throughout the Python for Everybody specialization. Across seven modules, I practiced:

Retrieving structured and unstructured data from websites and APIs

Parsing HTML, JSON, XML, and text

Modeling information in SQLite databases

Cleaning and transforming datasets

Visualizing meaningful patterns through interactive charts and word clouds

The course culminated in a multi-step, real-world workflow involving web spiders, data modeling, email dataset exploration, and layered visual analytics.

â¸»

ğŸ› ï¸ Tools Used

Python 3 for all scripting

SQLite (content.sqlite, index.sqlite)

Regular Expressions for pattern matching and cleanup

BeautifulSoup + urllib for web scraping

JSON and XML parsing

matplotlib & Google Charts for visualization

Command line for executing and debugging scripts

Screenshots, .py files, and Markdown documentation

â¸»

ğŸ“ Folder Structure

Each module is organized into its own directory:

module1-welcome-to-the-capstone

module2-building-a-search-engine

module3-exploring-data-sources

module4-spidering-and-modeling-email-data

module5-accessing-new-data-sources

module6-visualizing-email-data

module7-visualizing-new-data-sources

Each module folder includes:

âœ”ï¸ Python scripts

ğŸ“ Markdown reflections / notes

ğŸ“¸ Screenshot outputs (quizzes, spiders, SQL browser views, word clouds, charts, etc.)

ğŸ” Attempt folders (for Modules 2, 4, and 6), keeping all work transparent

â¸»

ğŸ“ Certification Path

ğŸŸ¢ Regular Certificate: Completed successfully (100% score)

ğŸ”´ Honors Certificate: Attempted Modules 2, 4, and 6.

First attempts did not pass

All work is archived in dedicated attempt folders

Second attempts underway (and documented)

This aligns with my GitHub philosophy: show the entire journey, not just the polished output.

â¸»

ğŸ’¡ Reflection

This capstone was both humbling and validating. It pushed me beyond isolated exercises and into full-stack data retrieval pipelines â€” from raw source to visual insight.

My biggest wins:

ğŸ•¸ï¸ Building spiders to crawl web pages efficiently

ğŸ§­ Extracting structured information using BeautifulSoup and regex

ğŸ—„ï¸ Translating JSON and XML into normalized SQL tables

ğŸ“Š Visualizing trends using Google Charts and D3.js

ğŸ§¹ Debugging real-world messy data and refining logic

Even though I didnâ€™t achieve the honors certificate on the first try, the process strengthened my debugging, documentation habits, and problem-solving resilience. My repository preserves the entire journey as transparent evidence of technical growth.

This course proved Iâ€™m capable of moving from tutorial-based learning to applied, end-to-end data engineering workflows â€” and Iâ€™m proud of the depth I gained.