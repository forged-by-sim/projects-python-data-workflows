# ğŸŒ M5 â€“ Raw Data Retrieval & Analysis Planning  
**Folder**: `m5-accessing-new-data-sources`  
**Focus**: Reflecting on data sourcing, early cleaning strategy, and planning the next steps for analysis  

â¸»

## ğŸ¯ Overview  
This stage focused on evaluating raw datasets and refining how to retrieve, clean, and prepare them for analysis. Rather than writing code, the task emphasized strategyâ€”documenting progress, identifying potential obstacles, and clarifying how to structure a meaningful analysis from real-world data sources.

â¸»

## ğŸ” Topics Explored

- Progress updates on chosen datasets  
- Retrieval techniques using web scraping or API methods  
- Common raw data challenges: formatting, missing fields, etc.  
- Structuring early analysis questions  
- Peer feedback on data preparation direction  

â¸»

## ğŸ› ï¸ Tools Referenced (Conceptual Only)

Although no scripts were created at this stage, several Python-related tools and workflows were discussed or reinforced:

- Python 3 data retrieval strategies  
- `urllib`, `requests`, `BeautifulSoup` (HTML scraping)  
- JSON / XML / CSV handling  
- APIs and data pipelines  
- Data cleaning workflows  
- Preparing data for SQLite or visualization libraries like `matplotlib`  

These tools become hands-on again in later stages of the analysis pipeline.

â¸»

## ğŸ§  Reflection  
This checkpoint helped map the transition from **raw data** to **analysis-ready structure**. By stepping back from the keyboard, I was able to articulate:

- What data I wanted to explore  
- Why it mattered in a broader context  
- How I planned to clean and prepare it  

This strategy-focused pause clarified next steps and sharpened my approach before returning to hands-on scripting.

---
